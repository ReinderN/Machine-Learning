{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98441deb",
   "metadata": {},
   "source": [
    "# Opgave DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde54c84",
   "metadata": {},
   "source": [
    "In deze opgave gaan we voor de verandering werken met de iris-dataset. We hebben hiervoor gekozen omdat het een fijne kleine en overzichtelijke dataset is en omdat deze inmiddels al voldoende is toegelicht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a75927",
   "metadata": {},
   "source": [
    "Omdat we nu unsupervised te werk gaan, maken we geen gebruik van de `y`-vector. We willen kijken of we een [DBSCAN-model](https://scikit-learn.org/stable/modules/clustering.html#dbscan) kunnen maken dat de data in verschillende klassen kan classificeren. Om deze classificatie inzichtelijk te maken, hebben we een hulpfunctie `plot_dbscan` gemaakt, die je hieronder ziet staan. Bestudeer eventueel deze code om een beeld te krijgen van hoe hij werkt en wat de bedoeling is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29a504",
   "metadata": {},
   "source": [
    "Run de onderstaande cel om de noodzakelijke imports uit te voeren."
   ]
  },
  {
   "cell_type": "code",
   "id": "30573311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T07:40:02.481756Z",
     "start_time": "2024-10-16T07:40:02.479200Z"
    }
   },
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "865c64f7",
   "metadata": {},
   "source": [
    "Run de onderstaande cel om de methode `plot_dbscan` te definiÃ«ren."
   ]
  },
  {
   "cell_type": "code",
   "id": "7da8a207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T07:40:02.496367Z",
     "start_time": "2024-10-16T07:40:02.492268Z"
    }
   },
   "source": [
    "def plot_dbscan(model, X, **labels):\n",
    "    core_mask = np.zeros_like(model.labels_, dtype=bool)\n",
    "    core_mask[model.core_sample_indices_] = True\n",
    "    anomalies_mask = model.labels_ == -1\n",
    "    non_core_mask = ~(core_mask | anomalies_mask)\n",
    "\n",
    "    cores = model.components_\n",
    "    anomalies = X[anomalies_mask]\n",
    "    non_cores = X[non_core_mask]\n",
    "    \n",
    "    plt.scatter(cores[:, 0], cores[:, 1], c=model.labels_[core_mask], marker='o', s=100, cmap=\"Paired\")\n",
    "    plt.scatter(cores[:, 0], cores[:, 1], c=model.labels_[core_mask], marker='^', s=20, label='klasse')\n",
    "    plt.scatter(anomalies[:, 0], anomalies[:, 1], c=\"r\", marker=\"x\", s=100, label='uitbijter')\n",
    "    plt.scatter(non_cores[:, 0], non_cores[:, 1], c=model.labels_[non_core_mask], marker=\".\", label='non-core')\n",
    "    \n",
    "    x_str = '$x_1$' if not 'xlabel' in labels else labels['xlabel']\n",
    "    y_str = '$x_2$' if not 'ylabel' in labels else labels['ylabel']\n",
    "    plt.xlabel(x_str, fontsize=14)\n",
    "    plt.ylabel(y_str, fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.title(f\"eps={model.eps:.2f}, min_samples={model.min_samples}\", fontsize=14)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "e2756703",
   "metadata": {},
   "source": [
    "Laad de iris-dataset van uit `sklearn-datasets`. Zoals tijdens het theoriecollege is toegelicht zijn &epsilon; (`eps`) en het aantal samples in de omgeving van het gekozen datapunt de belangrijkste parameters van DBSCAN. Maak verschillende modellen met (in ieder geval) de onderstaande waarden voor deze parameters. Maak telkens een plot en registreer het aantal klassen, uitbijters en non-core observaties.\n",
    "\n",
    "```\n",
    "  min_samples: [3, 4, 5, 7, 9]\n",
    "  eps{ [.1, .4, .55, .6, 1, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316a791f",
   "metadata": {},
   "source": [
    "Maak vervolgens een interessante visualisatie van deze gegevens om inzichtelijk te krijgen wat de effecten van de verschillende waarden voor deze parameters zijn. Kun je verklaren wat er gebeurt?"
   ]
  },
  {
   "cell_type": "code",
   "id": "edb1fa61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T07:40:02.506643Z",
     "start_time": "2024-10-16T07:40:02.503478Z"
    }
   },
   "source": [
    "min_samples = [3, 4, 5, 7, 9]\n",
    "eps = [.1, .4, .55, .6, 1, 2]\n",
    "\n",
    "X, y = load_iris(return_X_y=True)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T07:43:19.700799Z",
     "start_time": "2024-10-16T07:43:19.352323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for min_sample in min_samples:\n",
    "    for ep in eps:\n",
    "        model = DBSCAN(eps=ep, min_samples=min_sample)\n",
    "        model.fit(X)\n",
    "        plot_dbscan(model, X, xlabel='sepal length', ylabel='sepal width')\n",
    "        plt.show()"
   ],
   "id": "a4b81ecc32b8600f",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator DBSCAN() does not.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m model \u001B[38;5;241m=\u001B[39m DBSCAN()\n\u001B[1;32m     10\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m---> 11\u001B[0m grid_search\u001B[38;5;241m.\u001B[39mfit(X)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(grid_search\u001B[38;5;241m.\u001B[39mbest_params_)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m min_sample \u001B[38;5;129;01min\u001B[39;00m min_samples:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:872\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m    868\u001B[0m estimator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimator\n\u001B[1;32m    869\u001B[0m \u001B[38;5;66;03m# Here we keep a dict of scorers as is, and only convert to a\u001B[39;00m\n\u001B[1;32m    870\u001B[0m \u001B[38;5;66;03m# _MultimetricScorer at a later stage. Issue:\u001B[39;00m\n\u001B[1;32m    871\u001B[0m \u001B[38;5;66;03m# https://github.com/scikit-learn/scikit-learn/issues/27001\u001B[39;00m\n\u001B[0;32m--> 872\u001B[0m scorers, refit_metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_scorers(convert_multimetric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    874\u001B[0m X, y \u001B[38;5;241m=\u001B[39m indexable(X, y)\n\u001B[1;32m    875\u001B[0m params \u001B[38;5;241m=\u001B[39m _check_method_params(X, params\u001B[38;5;241m=\u001B[39mparams)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:805\u001B[0m, in \u001B[0;36mBaseSearchCV._get_scorers\u001B[0;34m(self, convert_multimetric)\u001B[0m\n\u001B[1;32m    803\u001B[0m     scorers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring\n\u001B[1;32m    804\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m--> 805\u001B[0m     scorers \u001B[38;5;241m=\u001B[39m check_scoring(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimator, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring)\n\u001B[1;32m    806\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    807\u001B[0m     scorers \u001B[38;5;241m=\u001B[39m _check_multimetric_scoring(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimator, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:951\u001B[0m, in \u001B[0;36mcheck_scoring\u001B[0;34m(estimator, scoring, allow_none)\u001B[0m\n\u001B[1;32m    949\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    950\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 951\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    952\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf no scoring is specified, the estimator passed should \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    953\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhave a \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m method. The estimator \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m does not.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m estimator\n\u001B[1;32m    954\u001B[0m     )\n",
      "\u001B[0;31mTypeError\u001B[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator DBSCAN() does not."
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
